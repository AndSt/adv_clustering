{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "28b7dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d4c4466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/andst/synology/phd/datasets/clustering/reproducing/Event\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "87394731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,2)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "955f271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = joblib.load(os.path.join(data_dir, \"Event_clu_init_300_1.00.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1739d62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 300)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0435363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"Event_word2wid.txt\")) as f:\n",
    "    event2id = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7e0542d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2serious': 1,\n",
       " '3novic': 2,\n",
       " '9new': 3,\n",
       " 'aaj': 4,\n",
       " 'aajtv': 5,\n",
       " 'aamaq': 6,\n",
       " 'aamirliaquat': 7,\n",
       " 'aap': 8,\n",
       " 'aapk': 9,\n",
       " 'ab': 10,\n",
       " 'abba': 11,\n",
       " 'abbassiya': 12,\n",
       " 'abc': 13,\n",
       " 'abcnew': 14,\n",
       " 'abdeslam': 15,\n",
       " 'abduct': 16,\n",
       " 'abdul': 17,\n",
       " 'ablaz': 18,\n",
       " 'aboard': 19,\n",
       " 'abrini': 20,\n",
       " 'absolut': 21,\n",
       " 'absurd': 22,\n",
       " 'abt': 23,\n",
       " 'abu': 24,\n",
       " 'abus': 25,\n",
       " 'ac': 26,\n",
       " 'acc': 27,\n",
       " 'acceler': 28,\n",
       " 'accept': 29,\n",
       " 'access': 30,\n",
       " 'accid': 31,\n",
       " 'accommod': 32,\n",
       " 'accomplic': 33,\n",
       " 'account': 34,\n",
       " 'accus': 35,\n",
       " 'achakzai': 36,\n",
       " 'act': 37,\n",
       " 'actagainstpak': 38,\n",
       " 'action': 39,\n",
       " 'activ': 40,\n",
       " 'activist': 41,\n",
       " 'actual': 42,\n",
       " 'ad': 43,\n",
       " 'adamawa': 44,\n",
       " 'adan': 45,\n",
       " 'add': 46,\n",
       " 'addit': 47,\n",
       " 'address': 48,\n",
       " 'adel': 49,\n",
       " 'aden': 50,\n",
       " 'administr': 51,\n",
       " 'admit': 52,\n",
       " 'advanc': 53,\n",
       " 'advic': 54,\n",
       " 'advis': 55,\n",
       " 'advoc': 56,\n",
       " 'aerial': 57,\n",
       " 'af': 58,\n",
       " 'affair': 59,\n",
       " 'affect': 60,\n",
       " 'affili': 61,\n",
       " 'afford': 62,\n",
       " 'afg': 63,\n",
       " 'afgh': 64,\n",
       " 'afghan': 65,\n",
       " 'afghani': 66,\n",
       " 'afghanistan': 67,\n",
       " 'afp': 68,\n",
       " 'afraid': 69,\n",
       " 'africa': 70,\n",
       " 'african': 71,\n",
       " 'aft': 72,\n",
       " 'aftermath': 73,\n",
       " 'afternoon': 74,\n",
       " 'aftr': 75,\n",
       " 'again': 76,\n",
       " 'agar': 77,\n",
       " 'age': 78,\n",
       " 'agen': 79,\n",
       " 'agenc': 80,\n",
       " 'agent': 81,\n",
       " 'aggress': 82,\n",
       " 'ago': 83,\n",
       " 'agre': 84,\n",
       " 'ahead': 85,\n",
       " 'ahm': 86,\n",
       " 'ahmadiyya': 87,\n",
       " 'ahmet': 88,\n",
       " 'ahrar': 89,\n",
       " 'aid': 90,\n",
       " 'aim': 91,\n",
       " 'air': 92,\n",
       " 'airbas': 93,\n",
       " 'aircraft': 94,\n",
       " 'airfield': 95,\n",
       " 'airlin': 96,\n",
       " 'airplan': 97,\n",
       " 'airpor': 98,\n",
       " 'airport': 99,\n",
       " 'airstrik': 100,\n",
       " 'aj': 101,\n",
       " 'akbar': 102,\n",
       " 'akhbar': 103,\n",
       " 'akhtar': 104,\n",
       " 'akp': 105,\n",
       " 'al': 106,\n",
       " 'aleppo': 107,\n",
       " 'alert': 108,\n",
       " 'alexandria': 109,\n",
       " 'algeria': 110,\n",
       " 'ali': 111,\n",
       " 'aliv': 112,\n",
       " 'aljazeera': 113,\n",
       " 'allah': 114,\n",
       " 'allahu': 115,\n",
       " 'allan': 116,\n",
       " 'alleg': 117,\n",
       " 'allegi': 118,\n",
       " 'alli': 119,\n",
       " 'allow': 120,\n",
       " 'almalki': 121,\n",
       " 'almight': 122,\n",
       " 'almighti': 123,\n",
       " 'alon': 124,\n",
       " 'alot': 125,\n",
       " 'alshabaab': 126,\n",
       " 'alshabab': 127,\n",
       " 'altafhussain': 128,\n",
       " 'amaq': 129,\n",
       " 'amaqag': 130,\n",
       " 'amaz': 131,\n",
       " 'ambassador': 132,\n",
       " 'ambul': 133,\n",
       " 'ambush': 134,\n",
       " 'ameen': 135,\n",
       " 'ameri': 136,\n",
       " 'america': 137,\n",
       " 'american': 138,\n",
       " 'amid': 139,\n",
       " 'amidst': 140,\n",
       " 'amisom': 141,\n",
       " 'ammi': 142,\n",
       " 'ammo': 143,\n",
       " 'ammunit': 144,\n",
       " 'amnesti': 145,\n",
       " 'analysi': 146,\n",
       " 'analyst': 147,\n",
       " 'anbar': 148,\n",
       " 'anchor': 149,\n",
       " 'android': 150,\n",
       " 'angel': 151,\n",
       " 'anger': 152,\n",
       " 'angri': 153,\n",
       " 'ani': 154,\n",
       " 'anim': 155,\n",
       " 'ank': 156,\n",
       " 'ankara': 157,\n",
       " 'ankaraattack': 158,\n",
       " 'ankarablast': 159,\n",
       " 'ankarabomb': 160,\n",
       " 'ankaraexplos': 161,\n",
       " 'anniversari': 162,\n",
       " 'announc': 163,\n",
       " 'anonym': 164,\n",
       " 'answer': 165,\n",
       " 'anti': 166,\n",
       " 'anwar': 167,\n",
       " 'anymor': 168,\n",
       " 'anytim': 169,\n",
       " 'ap': 170,\n",
       " 'apart': 171,\n",
       " 'apolog': 172,\n",
       " 'apologis': 173,\n",
       " 'app': 174,\n",
       " 'appal': 175,\n",
       " 'appar': 176,\n",
       " 'appeal': 177,\n",
       " 'appear': 178,\n",
       " 'applic': 179,\n",
       " 'appreci': 180,\n",
       " 'apprehend': 181,\n",
       " 'appris': 182,\n",
       " 'approach': 183,\n",
       " 'approx': 184,\n",
       " 'approxim': 185,\n",
       " 'april': 186,\n",
       " 'apsattack': 187,\n",
       " 'aqap': 188,\n",
       " 'aqim': 189,\n",
       " 'aqsa': 190,\n",
       " 'ar': 191,\n",
       " 'ara': 192,\n",
       " 'arab': 193,\n",
       " 'arabia': 194,\n",
       " 'arch': 195,\n",
       " 'area': 196,\n",
       " 'arena': 197,\n",
       " 'argu': 198,\n",
       " 'ari': 199,\n",
       " 'arif': 200,\n",
       " 'arm': 201,\n",
       " 'armi': 202,\n",
       " 'armour': 203,\n",
       " 'arnab': 204,\n",
       " 'arrang': 205,\n",
       " 'arrest': 206,\n",
       " 'arriv': 207,\n",
       " 'arson': 208,\n",
       " 'art': 209,\n",
       " 'articl': 210,\n",
       " 'artilleri': 211,\n",
       " 'artist': 212,\n",
       " 'asham': 213,\n",
       " 'ashraf': 214,\n",
       " 'asia': 215,\n",
       " 'asian': 216,\n",
       " 'ask': 217,\n",
       " 'assad': 218,\n",
       " 'assail': 219,\n",
       " 'assam': 220,\n",
       " 'assault': 221,\n",
       " 'assembl': 222,\n",
       " 'assert': 223,\n",
       " 'assist': 224,\n",
       " 'associ': 225,\n",
       " 'assur': 226,\n",
       " 'asylum': 227,\n",
       " 'atleast': 228,\n",
       " 'atroc': 229,\n",
       " 'atroci': 230,\n",
       " 'att': 231,\n",
       " 'atta': 232,\n",
       " 'attac': 233,\n",
       " 'attach': 234,\n",
       " 'attack': 235,\n",
       " 'attck': 236,\n",
       " 'attempt': 237,\n",
       " 'attend': 238,\n",
       " 'attent': 239,\n",
       " 'au': 240,\n",
       " 'aug': 241,\n",
       " 'august': 242,\n",
       " 'aurelien': 243,\n",
       " 'aussi': 244,\n",
       " 'australia': 245,\n",
       " 'australian': 246,\n",
       " 'author': 247,\n",
       " 'automat': 248,\n",
       " 'aveng': 249,\n",
       " 'avert': 250,\n",
       " 'aviv': 251,\n",
       " 'avoid': 252,\n",
       " 'aw': 253,\n",
       " 'await': 254,\n",
       " 'awaninew': 255,\n",
       " 'awar': 256,\n",
       " 'azad': 257,\n",
       " 'azb': 258,\n",
       " 'ba': 259,\n",
       " 'baba': 260,\n",
       " 'babi': 261,\n",
       " 'back': 262,\n",
       " 'background': 263,\n",
       " 'backpack': 264,\n",
       " 'bad': 265,\n",
       " 'bag': 266,\n",
       " 'baghdad': 267,\n",
       " 'baghdadi': 268,\n",
       " 'bagram': 269,\n",
       " 'bajwa': 270,\n",
       " 'bajwah': 271,\n",
       " 'bakal': 272,\n",
       " 'baloch': 273,\n",
       " 'balochi': 274,\n",
       " 'balochistan': 275,\n",
       " 'baluchistan': 276,\n",
       " 'ban': 277,\n",
       " 'band': 278,\n",
       " 'bank': 279,\n",
       " 'banner': 280,\n",
       " 'bar': 281,\n",
       " 'barack': 282,\n",
       " 'barbar': 283,\n",
       " 'barbarian': 284,\n",
       " 'bare': 285,\n",
       " 'barelvi': 286,\n",
       " 'barrack': 287,\n",
       " 'barrel': 288,\n",
       " 'barrist': 289,\n",
       " 'barzani': 290,\n",
       " 'bas': 291,\n",
       " 'base': 292,\n",
       " 'basi': 293,\n",
       " 'bassam': 294,\n",
       " 'bast': 295,\n",
       " 'bastard': 296,\n",
       " 'bastill': 297,\n",
       " 'bastilleday': 298,\n",
       " 'bataclan': 299,\n",
       " 'batch': 300,\n",
       " 'battalion': 301,\n",
       " 'battl': 302,\n",
       " 'bavarian': 303,\n",
       " 'bb4sp': 304,\n",
       " 'bbc': 305,\n",
       " 'bbcbreak': 306,\n",
       " 'bbcnew': 307,\n",
       " 'bbcworld': 308,\n",
       " 'bc': 309,\n",
       " 'be': 310,\n",
       " 'beach': 311,\n",
       " 'beachfront': 312,\n",
       " 'beachsid': 313,\n",
       " 'bear': 314,\n",
       " 'beast': 315,\n",
       " 'beat': 316,\n",
       " 'beauti': 317,\n",
       " 'beef': 318,\n",
       " 'befit': 319,\n",
       " 'began': 320,\n",
       " 'begin': 321,\n",
       " 'behest': 322,\n",
       " 'beirut': 323,\n",
       " 'bekel': 324,\n",
       " 'belgian': 325,\n",
       " 'belgiqu': 326,\n",
       " 'belgium': 327,\n",
       " 'believ': 328,\n",
       " 'belong': 329,\n",
       " 'belov': 330,\n",
       " 'belt': 331,\n",
       " 'ben': 332,\n",
       " 'beneficiari': 333,\n",
       " 'benefit': 334,\n",
       " 'bengal': 335,\n",
       " 'bereav': 336,\n",
       " 'berlin': 337,\n",
       " 'berni': 338,\n",
       " 'besikta': 339,\n",
       " 'bet': 340,\n",
       " 'bethlehem': 341,\n",
       " 'bett': 342,\n",
       " 'beyo': 343,\n",
       " 'bfmtv': 344,\n",
       " 'bhakt': 345,\n",
       " 'bhutto': 346,\n",
       " 'bias': 347,\n",
       " 'bibi': 348,\n",
       " 'bicycl': 349,\n",
       " 'bid': 350,\n",
       " 'biden': 351,\n",
       " 'big': 352,\n",
       " 'bigger': 353,\n",
       " 'biggest': 354,\n",
       " 'bihar': 355,\n",
       " 'bilaw': 356,\n",
       " 'billion': 357,\n",
       " 'bilt': 358,\n",
       " 'birthday': 359,\n",
       " 'bishop': 360,\n",
       " 'bit': 361,\n",
       " 'bizarr': 362,\n",
       " 'bjp': 363,\n",
       " 'bl': 364,\n",
       " 'black': 365,\n",
       " 'blackout': 366,\n",
       " 'blame': 367,\n",
       " 'blank': 368,\n",
       " 'blast': 369,\n",
       " 'blaze': 370,\n",
       " 'bleed': 371,\n",
       " 'bless': 372,\n",
       " 'blew': 373,\n",
       " 'blind': 374,\n",
       " 'block': 375,\n",
       " 'blog': 376,\n",
       " 'blood': 377,\n",
       " 'bloodbath': 378,\n",
       " 'bloodi': 379,\n",
       " 'bloodsh': 380,\n",
       " 'bloomberg': 381,\n",
       " 'blow': 382,\n",
       " 'blown': 383,\n",
       " 'blue': 384,\n",
       " 'bn': 385,\n",
       " 'bo': 386,\n",
       " 'board': 387,\n",
       " 'boardwalk': 388,\n",
       " 'bodi': 389,\n",
       " 'bokep': 390,\n",
       " 'bokepabg': 391,\n",
       " 'boko': 392,\n",
       " 'bokoharam': 393,\n",
       " 'bollywood': 394,\n",
       " 'bom': 395,\n",
       " 'bomb': 396,\n",
       " 'bombard': 397,\n",
       " 'bomber': 398,\n",
       " 'bombmak': 399,\n",
       " 'bone': 400,\n",
       " 'book': 401,\n",
       " 'boost': 402,\n",
       " 'border': 403,\n",
       " 'born': 404,\n",
       " 'borno': 405,\n",
       " 'boss': 406,\n",
       " 'boston': 407,\n",
       " 'bother': 408,\n",
       " 'boundari': 409,\n",
       " 'bow': 410,\n",
       " 'bowi': 411,\n",
       " 'boy': 412,\n",
       " 'boycott': 413,\n",
       " 'br': 414,\n",
       " 'brainwash': 415,\n",
       " 'brave': 416,\n",
       " 'braveheart': 417,\n",
       " 'braveri': 418,\n",
       " 'breach': 419,\n",
       " 'break': 420,\n",
       " 'breakaway': 421,\n",
       " 'breakingnew': 422,\n",
       " 'breeden': 423,\n",
       " 'breitbart': 424,\n",
       " 'brenner': 425,\n",
       " 'brief': 426,\n",
       " 'brigad': 427,\n",
       " 'bring': 428,\n",
       " 'britain': 429,\n",
       " 'british': 430,\n",
       " 'briton': 431,\n",
       " 'broadcast': 432,\n",
       " 'broke': 433,\n",
       " 'broken': 434,\n",
       " 'brooklyn': 435,\n",
       " 'brother': 436,\n",
       " 'brought': 437,\n",
       " 'brussel': 438,\n",
       " 'brusselsairport': 439,\n",
       " 'brusselsattack': 440,\n",
       " 'brutal': 441,\n",
       " 'bruxell': 442,\n",
       " 'bt': 443,\n",
       " 'btw': 444,\n",
       " 'buddi': 445,\n",
       " 'bugti': 446,\n",
       " 'buhari': 447,\n",
       " 'build': 448,\n",
       " 'bullet': 449,\n",
       " 'bulut': 450,\n",
       " 'burden': 451,\n",
       " 'burhan': 452,\n",
       " 'buri': 453,\n",
       " 'burn': 454,\n",
       " 'burnt': 455,\n",
       " 'bursa': 456,\n",
       " 'burst': 457,\n",
       " 'bus': 458,\n",
       " 'buse': 459,\n",
       " 'busi': 460,\n",
       " 'busiest': 461,\n",
       " 'butcher': 462,\n",
       " 'buy': 463,\n",
       " 'ca': 464,\n",
       " 'cab': 465,\n",
       " 'cabinet': 466,\n",
       " 'cafe': 467,\n",
       " 'cairo': 468,\n",
       " 'cairoblast': 469,\n",
       " 'cairobomb': 470,\n",
       " 'cairocathedr': 471,\n",
       " 'cal': 472,\n",
       " 'calam': 473,\n",
       " 'calcul': 474,\n",
       " 'caliph': 475,\n",
       " 'call': 476,\n",
       " 'calm': 477,\n",
       " 'cam': 478,\n",
       " 'camera': 479,\n",
       " 'cameraman': 480,\n",
       " 'cameron': 481,\n",
       " 'cameroon': 482,\n",
       " 'camp': 483,\n",
       " 'campaign': 484,\n",
       " 'campus': 485,\n",
       " 'canada': 486,\n",
       " 'canadian': 487,\n",
       " 'cancel': 488,\n",
       " 'cancer': 489,\n",
       " 'candi': 490,\n",
       " 'candid': 491,\n",
       " 'candl': 492,\n",
       " 'capit': 493,\n",
       " 'capitol': 494,\n",
       " 'captur': 495,\n",
       " 'car': 496,\n",
       " 'carbomb': 497,\n",
       " 'card': 498,\n",
       " 'care': 499,\n",
       " 'carnag': 500,\n",
       " 'carpet': 501,\n",
       " 'carri': 502,\n",
       " 'carter': 503,\n",
       " 'cartoon': 504,\n",
       " 'case': 505,\n",
       " 'castl': 506,\n",
       " 'castro': 507,\n",
       " 'casualti': 508,\n",
       " 'catch': 509,\n",
       " 'cathedr': 510,\n",
       " 'caught': 511,\n",
       " 'caus': 512,\n",
       " 'caution': 513,\n",
       " 'cbc': 514,\n",
       " 'cbs': 515,\n",
       " 'cc': 516,\n",
       " 'cctv': 517,\n",
       " 'cdnpoli': 518,\n",
       " 'ceas': 519,\n",
       " 'ceasefir': 520,\n",
       " 'celeb': 521,\n",
       " 'celebr': 522,\n",
       " 'celebratin': 523,\n",
       " 'cell': 524,\n",
       " 'cellphon': 525,\n",
       " 'centcom': 526,\n",
       " 'center': 527,\n",
       " 'centr': 528,\n",
       " 'central': 529,\n",
       " 'centuri': 530,\n",
       " 'ceremoni': 531,\n",
       " 'ch': 532,\n",
       " 'chair': 533,\n",
       " 'chairman': 534,\n",
       " 'chan': 535,\n",
       " 'chanc': 536,\n",
       " 'chancellor': 537,\n",
       " 'chang': 538,\n",
       " 'channel': 539,\n",
       " 'channelnewsasia': 540,\n",
       " 'chant': 541,\n",
       " 'chao': 542,\n",
       " 'chapel': 543,\n",
       " 'chapter': 544,\n",
       " 'charg': 545,\n",
       " 'chariti': 546,\n",
       " 'charli': 547,\n",
       " 'charliehebdo': 548,\n",
       " 'cheap': 549,\n",
       " 'check': 550,\n",
       " 'checkpoint': 551,\n",
       " 'cheffou': 552,\n",
       " 'chemic': 553,\n",
       " 'chhattisgarh': 554,\n",
       " 'chi': 555,\n",
       " 'chicago': 556,\n",
       " 'chief': 557,\n",
       " 'child': 558,\n",
       " 'children': 559,\n",
       " 'chill': 560,\n",
       " 'china': 561,\n",
       " 'chlorin': 562,\n",
       " 'chocol': 563,\n",
       " 'choos': 564,\n",
       " 'christian': 565,\n",
       " 'churc': 566,\n",
       " 'church': 567,\n",
       " 'ci': 568,\n",
       " 'cia': 569,\n",
       " 'cid': 570,\n",
       " 'cit': 571,\n",
       " 'cite': 572,\n",
       " 'citi': 573,\n",
       " 'citizen': 574,\n",
       " 'civil': 575,\n",
       " 'civilhospit': 576,\n",
       " 'civilian': 577,\n",
       " 'civillian': 578,\n",
       " 'claim': 579,\n",
       " 'clamp': 580,\n",
       " 'clash': 581,\n",
       " 'cld': 582,\n",
       " 'clean': 583,\n",
       " 'clear': 584,\n",
       " 'climb': 585,\n",
       " 'clinic': 586,\n",
       " 'clinton': 587,\n",
       " 'close': 588,\n",
       " 'club': 589,\n",
       " 'clue': 590,\n",
       " 'cm': 591,\n",
       " 'cmh': 592,\n",
       " 'cnic': 593,\n",
       " 'cnn': 594,\n",
       " 'cnnbrk': 595,\n",
       " 'coa': 596,\n",
       " 'coalit': 597,\n",
       " 'coast': 598,\n",
       " 'coastal': 599,\n",
       " 'code': 600,\n",
       " 'coincid': 601,\n",
       " 'col': 602,\n",
       " 'cold': 603,\n",
       " 'coll': 604,\n",
       " 'collaps': 605,\n",
       " 'colleagu': 606,\n",
       " 'collect': 607,\n",
       " 'colonel': 608,\n",
       " 'color': 609,\n",
       " 'colour': 610,\n",
       " 'columbus': 611,\n",
       " 'column': 612,\n",
       " 'comb': 613,\n",
       " 'combat': 614,\n",
       " 'come': 615,\n",
       " 'comfort': 616,\n",
       " 'command': 617,\n",
       " 'commando': 618,\n",
       " 'commemor': 619,\n",
       " 'comment': 620,\n",
       " 'commit': 621,\n",
       " 'committe': 622,\n",
       " 'common': 623,\n",
       " 'communiti': 624,\n",
       " 'commut': 625,\n",
       " 'compar': 626,\n",
       " 'compens': 627,\n",
       " 'complet': 628,\n",
       " 'complex': 629,\n",
       " 'compound': 630,\n",
       " 'concern': 631,\n",
       " 'concert': 632,\n",
       " 'conclus': 633,\n",
       " 'concret': 634,\n",
       " 'condem': 635,\n",
       " 'condemn': 636,\n",
       " 'condemnextrem': 637,\n",
       " 'condit': 638,\n",
       " 'condol': 639,\n",
       " 'conduct': 640,\n",
       " 'confer': 641,\n",
       " 'confid': 642,\n",
       " 'confirm': 643,\n",
       " 'conflict': 644,\n",
       " 'confus': 645,\n",
       " 'congress': 646,\n",
       " 'connect': 647,\n",
       " 'conquer': 648,\n",
       " 'conscienc': 649,\n",
       " 'consid': 650,\n",
       " 'conspir': 651,\n",
       " 'conspiraci': 652,\n",
       " 'constru': 653,\n",
       " 'consul': 654,\n",
       " 'consum': 655,\n",
       " 'cont': 656,\n",
       " 'contact': 657,\n",
       " 'content': 658,\n",
       " 'context': 659,\n",
       " 'continu': 660,\n",
       " 'contractor': 661,\n",
       " 'control': 662,\n",
       " 'convert': 663,\n",
       " 'convict': 664,\n",
       " 'convoy': 665,\n",
       " 'cook': 666,\n",
       " 'cool': 667,\n",
       " 'coordin': 668,\n",
       " 'cop': 669,\n",
       " 'copi': 670,\n",
       " 'copt': 671,\n",
       " 'coptic': 672,\n",
       " 'core': 673,\n",
       " 'corner': 674,\n",
       " 'correct': 675,\n",
       " 'corridor': 676,\n",
       " 'corrupt': 677,\n",
       " 'cost': 678,\n",
       " 'cotedivoir': 679,\n",
       " 'council': 680,\n",
       " 'count': 681,\n",
       " 'counter': 682,\n",
       " 'counterattack': 683,\n",
       " 'countless': 684,\n",
       " 'countri': 685,\n",
       " 'countrymen': 686,\n",
       " 'countrysid': 687,\n",
       " 'coupl': 688,\n",
       " 'courag': 689,\n",
       " 'court': 690,\n",
       " 'courthous': 691,\n",
       " 'cousin': 692,\n",
       " 'cover': 693,\n",
       " 'coverag': 694,\n",
       " 'cow': 695,\n",
       " 'coward': 696,\n",
       " 'cowardic': 697,\n",
       " 'coz': 698,\n",
       " 'cpec': 699,\n",
       " 'crackdown': 700,\n",
       " 'crash': 701,\n",
       " 'crass': 702,\n",
       " 'crazi': 703,\n",
       " 'cream': 704,\n",
       " 'creat': 705,\n",
       " 'credibl': 706,\n",
       " 'credit': 707,\n",
       " 'cri': 708,\n",
       " 'cricket': 709,\n",
       " 'crime': 710,\n",
       " 'crimin': 711,\n",
       " 'crisi': 712,\n",
       " 'critic': 713,\n",
       " 'criticis': 714,\n",
       " 'cross': 715,\n",
       " 'crowd': 716,\n",
       " 'crpf': 717,\n",
       " 'cruel': 718,\n",
       " 'crumbl': 719,\n",
       " 'crush': 720,\n",
       " 'cruz': 721,\n",
       " 'cs': 722,\n",
       " 'ctv': 723,\n",
       " 'cue': 724,\n",
       " 'culprit': 725,\n",
       " 'cultur': 726,\n",
       " 'current': 727,\n",
       " 'custodi': 728,\n",
       " 'custom': 729,\n",
       " 'cut': 730,\n",
       " \"d'ivoir\": 731,\n",
       " 'da': 732,\n",
       " 'daallo': 733,\n",
       " 'dad': 734,\n",
       " 'daesh': 735,\n",
       " 'dahir': 736,\n",
       " 'daili': 737,\n",
       " 'dailymail': 738,\n",
       " 'dalai': 739,\n",
       " 'dalbir': 740,\n",
       " 'dalit': 741,\n",
       " 'dalla': 742,\n",
       " 'dalori': 743,\n",
       " 'damag': 744,\n",
       " 'damascus': 745,\n",
       " 'damn': 746,\n",
       " 'dan': 747,\n",
       " 'danc': 748,\n",
       " 'danger': 749,\n",
       " 'dantewada': 750,\n",
       " 'dark': 751,\n",
       " 'dastard': 752,\n",
       " 'databas': 753,\n",
       " 'date': 754,\n",
       " 'daughter': 755,\n",
       " 'david': 756,\n",
       " 'davutoglu': 757,\n",
       " 'dawn': 758,\n",
       " 'dawnnew': 759,\n",
       " 'day': 760,\n",
       " 'daylong': 761,\n",
       " 'dead': 762,\n",
       " 'deadliest': 763,\n",
       " 'deal': 764,\n",
       " 'dear': 765,\n",
       " 'death': 766,\n",
       " 'debat': 767,\n",
       " 'debri': 768,\n",
       " 'decad': 769,\n",
       " 'deceas': 770,\n",
       " 'decid': 771,\n",
       " 'decim': 772,\n",
       " 'decis': 773,\n",
       " 'declar': 774,\n",
       " 'deep': 775,\n",
       " 'deepest': 776,\n",
       " 'deepli': 777,\n",
       " 'defeat': 778,\n",
       " 'defeatthi': 779,\n",
       " 'defenc': 780,\n",
       " 'defend': 781,\n",
       " 'defens': 782,\n",
       " 'defer': 783,\n",
       " 'definit': 784,\n",
       " 'deflect': 785,\n",
       " 'deir': 786,\n",
       " 'deirezzor': 787,\n",
       " 'deleg': 788,\n",
       " 'delet': 789,\n",
       " 'delhi': 790,\n",
       " 'deli': 791,\n",
       " 'deliber': 792,\n",
       " 'demand': 793,\n",
       " 'demis': 794,\n",
       " 'democraci': 795,\n",
       " 'democrat': 796,\n",
       " 'demonstr': 797,\n",
       " 'deni': 798,\n",
       " 'denial': 799,\n",
       " 'denounc': 800,\n",
       " 'depart': 801,\n",
       " 'departur': 802,\n",
       " 'deplor': 803,\n",
       " 'deploy': 804,\n",
       " 'deport': 805,\n",
       " 'depress': 806,\n",
       " 'dept': 807,\n",
       " 'deputi': 808,\n",
       " 'der': 809,\n",
       " 'derail': 810,\n",
       " 'des': 811,\n",
       " 'describ': 812,\n",
       " 'deserv': 813,\n",
       " 'design': 814,\n",
       " 'despair': 815,\n",
       " 'desper': 816,\n",
       " 'despic': 817,\n",
       " 'destroy': 818,\n",
       " 'detail': 819,\n",
       " 'detain': 820,\n",
       " 'deter': 821,\n",
       " 'determin': 822,\n",
       " 'deton': 823,\n",
       " 'devast': 824,\n",
       " 'develop': 825,\n",
       " 'devic': 826,\n",
       " 'devilish': 827,\n",
       " 'devout': 828,\n",
       " 'dg': 829,\n",
       " 'dgmo': 830,\n",
       " 'dgp': 831,\n",
       " 'dha': 832,\n",
       " 'dhoot': 833,\n",
       " 'di': 834,\n",
       " 'diaa': 835,\n",
       " 'dictat': 836,\n",
       " 'die': 837,\n",
       " 'differ': 838,\n",
       " 'difficult': 839,\n",
       " 'dig': 840,\n",
       " 'digniti': 841,\n",
       " 'diner': 842,\n",
       " 'dinner': 843,\n",
       " 'diplomat': 844,\n",
       " 'direct': 845,\n",
       " 'director': 846,\n",
       " 'dirti': 847,\n",
       " 'disast': 848,\n",
       " 'discord': 849,\n",
       " 'discov': 850,\n",
       " 'discredit': 851,\n",
       " 'discuss': 852,\n",
       " 'disgust': 853,\n",
       " 'dismay': 854,\n",
       " 'dispatch': 855,\n",
       " 'display': 856,\n",
       " 'dispos': 857,\n",
       " 'distanc': 858,\n",
       " 'distress': 859,\n",
       " 'district': 860,\n",
       " 'disturb': 861,\n",
       " 'divert': 862,\n",
       " 'divid': 863,\n",
       " 'divis': 864,\n",
       " 'dixon': 865,\n",
       " 'diyarbakir': 866,\n",
       " 'dizengoff': 867,\n",
       " 'dj': 868,\n",
       " 'dlvr': 869,\n",
       " 'dna': 870,\n",
       " 'doctor': 871,\n",
       " 'dod': 872,\n",
       " 'dog': 873,\n",
       " 'dogra': 874,\n",
       " 'domest': 875,\n",
       " 'domin': 876,\n",
       " 'donald': 877,\n",
       " 'donat': 878,\n",
       " 'donor': 879,\n",
       " 'dormitori': 880,\n",
       " 'dou': 881,\n",
       " 'doubl': 882,\n",
       " 'doubt': 883,\n",
       " 'doval': 884,\n",
       " 'down': 885,\n",
       " 'downtown': 886,\n",
       " 'dozen': 887,\n",
       " 'dr': 888,\n",
       " 'drama': 889,\n",
       " 'dramat': 890,\n",
       " 'dream': 891,\n",
       " 'dress': 892,\n",
       " 'drink': 893,\n",
       " 'drive': 894,\n",
       " 'driven': 895,\n",
       " 'driver': 896,\n",
       " 'drone': 897,\n",
       " 'drop': 898,\n",
       " 'drove': 899,\n",
       " 'dtn': 900,\n",
       " 'du': 901,\n",
       " 'dua': 902,\n",
       " 'dual': 903,\n",
       " 'dubai': 904,\n",
       " 'dunya': 905,\n",
       " 'dutch': 906,\n",
       " 'duti': 907,\n",
       " 'dw': 908,\n",
       " 'earli': 909,\n",
       " 'earlier': 910,\n",
       " 'earn': 911,\n",
       " 'earth': 912,\n",
       " 'eas': 913,\n",
       " 'easi': 914,\n",
       " 'easier': 915,\n",
       " 'east': 916,\n",
       " 'easter': 917,\n",
       " 'eastern': 918,\n",
       " 'eastersunday': 919,\n",
       " 'eat': 920,\n",
       " 'econom': 921,\n",
       " 'economi': 922,\n",
       " 'economist': 923,\n",
       " 'edg': 924,\n",
       " 'educ': 925,\n",
       " 'effect': 926,\n",
       " 'effecte': 927,\n",
       " 'effort': 928,\n",
       " 'eg': 929,\n",
       " 'egypt': 930,\n",
       " 'egyptian': 931,\n",
       " 'eid': 932,\n",
       " 'eiffel': 933,\n",
       " 'el': 934,\n",
       " 'elder': 935,\n",
       " 'elect': 936,\n",
       " 'elimin': 937,\n",
       " 'em': 938,\n",
       " 'embassi': 939,\n",
       " 'embolden': 940,\n",
       " 'emerg': 941,\n",
       " 'emot': 942,\n",
       " 'empir': 943,\n",
       " 'employ': 944,\n",
       " 'employe': 945,\n",
       " 'en': 946,\n",
       " 'encount': 947,\n",
       " 'encourag': 948,\n",
       " 'end': 949,\n",
       " 'endgam': 950,\n",
       " 'endtimesnew': 951,\n",
       " 'enemi': 952,\n",
       " 'enew': 953,\n",
       " 'enforc': 954,\n",
       " 'engag': 955,\n",
       " 'english': 956,\n",
       " 'enjoy': 957,\n",
       " 'ensur': 958,\n",
       " 'enter': 959,\n",
       " 'entertain': 960,\n",
       " 'entir': 961,\n",
       " 'entranc': 962,\n",
       " 'entri': 963,\n",
       " 'envoy': 964,\n",
       " 'equal': 965,\n",
       " 'equip': 966,\n",
       " 'erad': 967,\n",
       " 'erciy': 968,\n",
       " 'erdo': 969,\n",
       " 'erdogan': 970,\n",
       " 'error': 971,\n",
       " 'erupt': 972,\n",
       " 'escal': 973,\n",
       " 'escap': 974,\n",
       " 'esp': 975,\n",
       " 'essenc': 976,\n",
       " 'establish': 977,\n",
       " 'estim': 978,\n",
       " 'etfal': 979,\n",
       " 'etoil': 980,\n",
       " 'etribun': 981,\n",
       " 'euronew': 982,\n",
       " 'europ': 983,\n",
       " 'european': 984,\n",
       " 'evacu': 985,\n",
       " 'eve': 986,\n",
       " 'even': 987,\n",
       " 'event': 988,\n",
       " 'everyon': 989,\n",
       " 'everytim': 990,\n",
       " 'evid': 991,\n",
       " 'evil': 992,\n",
       " 'evok': 993,\n",
       " 'exact': 994,\n",
       " 'exam': 995,\n",
       " 'examin': 996,\n",
       " 'excel': 997,\n",
       " 'exchang': 998,\n",
       " 'exclus': 999,\n",
       " 'excus': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3621bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = joblib.load(os.path.join(data_dir, \"Event_word2vec_300.pkl\"))\n",
    "with open(os.path.join(data_dir, \"Event_word2wid.txt\")) as f:\n",
    "    event2id = json.load(f)\n",
    "\n",
    "word_embs = np.zeros((len(event2id), vec.get(\"break\").shape[0]))\n",
    "word_embs.shape\n",
    "for key, val in event2id.items():\n",
    "    word_embs[val - 1] = vec.get(key)\n",
    "word_embs = torch.from_numpy(word_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b98bc0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 0\n",
    "for line in lines:\n",
    "    if len(line[\"tokenids\"]) > m:\n",
    "        m = len(line[\"tokenids\"])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94d539bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(data_dir, \"Event_docarr.txt\")) as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [json.loads(l) for l in lines]\n",
    "\n",
    "padded_length = 0\n",
    "for line in lines:\n",
    "    if len(line[\"tokenids\"]) > padded_length:\n",
    "        padded_length = len(line[\"tokenids\"])\n",
    "print(padded_length)\n",
    "samples = []\n",
    "masks = []\n",
    "labels = []\n",
    "\n",
    "for line in lines:\n",
    "    labels.append(line[\"topic\"])\n",
    "    ids = line[\"tokenids\"]\n",
    "    ids = np.array([i - 1 for i in ids])\n",
    "    samples.append(torch.from_numpy(ids))\n",
    "    mask = np.zeros((padded_length,))\n",
    "    mask[0:len(ids)] = 1\n",
    "    masks.append(mask)\n",
    "    \n",
    "labels = torch.from_numpy(np.array(labels))\n",
    "samples = torch.nn.utils.rnn.pad_sequence(samples).T\n",
    "masks = torch.from_numpy(np.array(masks))\n",
    "\n",
    "assert masks.shape == samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72d59aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 419, 2676, 2454, 2848, 2947, 1506, 2608, 1424, 3095,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [ 419, 2681, 1093,  528, 2946,  250,  507, 2454,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [ 419, 2965,  234, 2946,  250, 1506, 1453, 1724, 2969, 2085,  576,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [1453, 2946,  250, 2676, 2965,  234, 2901, 2454, 1453,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [2676,  234,  526, 2946,  250, 3261, 2618, 3160, 2840,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [ 419, 1453, 2946,  250, 2676, 2965,  234, 2901, 2454,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [1451, 2454, 3261, 2676,  866, 2848, 2946,  250,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [ 419, 1556, 2681, 3261, 2946,  250,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [ 761,  712, 3261,  264, 1385, 2946,  250, 2676, 2677,  510,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [ 761, 3261, 2676,  866, 2848, 2946,  250,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01c973f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26619, 0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "94beb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adv_clustering.loader import get_dataloader\n",
    "\n",
    "\n",
    "word_embs, train_loader = get_dataloader(data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "438b4e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  ..., 68., 68., 68.])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a9e40390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3314, 300])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1ae274ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([64, 300, 18]) torch.Size([64, 18])\n"
     ]
    }
   ],
   "source": [
    "from adv_clustering.model import ARL\n",
    "\n",
    "\n",
    "model = ARL(word_vecs=word_embs, num_clusters=68)\n",
    "\n",
    "i = 0\n",
    "for batch in train_loader:\n",
    "    print(i)\n",
    "    i += 1\n",
    "    \n",
    "    labels = batch.pop(\"labels\")\n",
    "    d, d_reconstructed, d_neg = model(**batch)\n",
    "    if i is not None:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "57114277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x14e6bf190>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e3b2d55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:18<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  -0.9497871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:04<00:00, 90.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.13001991059017995, 'nmi': 0.1702980351993078, 'ami': 0.1532821942776451, 'ari': 0.045795328720022066}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:19<00:00, 21.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:19<00:00, 21.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:19<00:00, 21.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:19<00:00, 21.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:19<00:00, 20.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  -0.94103986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:04<00:00, 90.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.13005747774146287, 'nmi': 0.17020085647180005, 'ami': 0.15316939032614438, 'ari': 0.04593576482226357}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:18<00:00, 21.93it/s]\n",
      " 30%|███████████████████████████████████████████████████████████████▌                                                                                                                                                       | 123/416 [00:05<00:14, 20.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [189], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m t \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/adv_clustering/notebooks/../adv_clustering/trainer.py:56\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, data_loader, num_epochs, lr)\u001b[0m\n\u001b[1;32m     54\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# my_lr_scheduler.step(int(i / 50))\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[43mmy_optim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m my_lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# my_lr_scheduler.step()\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/virtual-envs/adv_clustering/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/virtual-envs/adv_clustering/lib/python3.8/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/virtual-envs/adv_clustering/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/virtual-envs/adv_clustering/lib/python3.8/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.cache/virtual-envs/adv_clustering/lib/python3.8/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/virtual-envs/adv_clustering/lib/python3.8/site-packages/torch/optim/adam.py:305\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from adv_clustering.trainer import Trainer\n",
    "\n",
    "\n",
    "model = ARL(word_vecs=word_embs, num_clusters=64)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "t = Trainer(model=model, device=device)\n",
    "t.train(data_loader=train_loader, lr=1e-3, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c21d7f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:05<00:00, 77.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.19760321574814982, 'nmi': 0.4224931538035421, 'ami': 0.38646250805477306, 'ari': 0.13068880017751477}\n"
     ]
    }
   ],
   "source": [
    "t.evaluate(train_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "142526ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 15, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.ones((3, 6)).unsqueeze(1).repeat(1, 15, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "580aaf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cosine_similarity(torch.ones((2,2, 4)), torch.ones((2,2,4)), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6633585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 40]) torch.Size([2, 40]) torch.Size([2, 16, 40])\n"
     ]
    }
   ],
   "source": [
    "print(d.shape, d_reconstructed.shape, d_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62ebc2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8672, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adv_clustering.trainer import J1_loss\n",
    "\n",
    "J1_loss(d, d_reconstructed, d_neg, margin=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
